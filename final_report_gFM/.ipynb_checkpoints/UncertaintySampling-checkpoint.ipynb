{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "easy_train = pd.read_csv('./Data/EASY_TRAIN.csv', header=None)\n",
    "easy_test = pd.read_csv('./Data/EASY_TEST.csv', header=None)\n",
    "\n",
    "moderate_train = pd.read_csv('./Data/MODERATE_TRAIN.csv', header=None)\n",
    "moderate_test = pd.read_csv('./Data/MODERATE_TEST.csv', header=None)\n",
    "\n",
    "difficult_train = pd.read_csv('./Data/DIFFICULT_TRAIN.csv', header=None)\n",
    "difficult_test = pd.read_csv('./Data/DIFFICULT_TEST.csv', header=None)\n",
    "\n",
    "easy_blind = pd.read_csv('./Data/EASY_BLINDED.csv', header=None).loc[:,1:].values\n",
    "moderate_blind = pd.read_csv('./Data/MODERATE_BLINDED.csv', header=None).loc[:,1:].values\n",
    "difficult_blind = pd.read_csv('./Data/DIFFICULT_BLINDED.csv', header=None).loc[:,1:].values\n",
    "\n",
    "easy_trainX = easy_train.loc[:,:25].values\n",
    "easy_trainY = easy_train.loc[:,26].values\n",
    "easy_testX = easy_test.loc[:,:25].values\n",
    "easy_testY = easy_test.loc[:,26].values\n",
    "\n",
    "moderate_trainX = moderate_train.loc[:,:25].values\n",
    "moderate_trainY = moderate_train.loc[:,26].values\n",
    "moderate_testX = moderate_test.loc[:,:25].values\n",
    "moderate_testY = moderate_test.loc[:,26].values\n",
    "\n",
    "difficult_trainX = difficult_train.loc[:,:51].values\n",
    "difficult_trainY = difficult_train.loc[:,52].values\n",
    "difficult_testX = difficult_test.loc[:,:51].values\n",
    "difficult_testY = difficult_test.loc[:,52].values\n",
    "\n",
    "labelMapping = {j:i for i,j in enumerate(np.unique(easy_trainY))}\n",
    "labelMapping_reverse = {i:j for i,j in enumerate(np.unique(easy_trainY))}\n",
    "easy_trainY_numeric = np.array([labelMapping[i] for i in easy_trainY])\n",
    "easy_testY_numeric = np.array([labelMapping[i] for i in easy_testY])\n",
    "\n",
    "moderate_trainY_numeric = np.array([labelMapping[i] for i in moderate_trainY])\n",
    "moderate_testY_numeric = np.array([labelMapping[i] for i in moderate_testY])\n",
    "\n",
    "difficult_trainY_numeric = np.array([labelMapping[i] for i in difficult_trainY])\n",
    "difficult_testY_numeric = np.array([labelMapping[i] for i in difficult_testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TAG = 'MODERATE'\n",
    "\n",
    "if TAG == 'EASY':\n",
    "    X_train, y_train = easy_trainX, easy_trainY_numeric\n",
    "    X_test, y_test = easy_testX, easy_testY_numeric\n",
    "    X_blind = easy_blind\n",
    "elif TAG == 'MODERATE':\n",
    "    X_train, y_train = moderate_trainX, moderate_trainY_numeric\n",
    "    X_test, y_test = moderate_testX, moderate_testY_numeric\n",
    "    X_blind = moderate_blind\n",
    "elif TAG == 'DIFFICULT':\n",
    "    X_train, y_train = difficult_trainX, difficult_trainY_numeric\n",
    "    X_test, y_test = difficult_testX, difficult_testY_numeric\n",
    "    X_blind = difficult_blind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce primary result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from libact.base.dataset import Dataset\n",
    "from libact.models import LogisticRegression\n",
    "from libact.query_strategies import UncertaintySampling, RandomSampling\n",
    "from libact.labelers import IdealLabeler\n",
    "from libact.query_strategies import ActiveLearningByLearning\n",
    "from libact.query_strategies import HintSVM, QUIRE\n",
    "from libact.query_strategies import UncertaintySampling, VarianceReduction\n",
    "from libact.models import LogisticRegression\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "import copy\n",
    "\n",
    "n_labeled = 100\n",
    "\n",
    "trn_ds = Dataset(X_train.astype('float64'), np.concatenate([y_train[:n_labeled].astype('float64'), [None] * (len(y_train) - n_labeled)]))\n",
    "tst_ds = Dataset(X_test.astype('float64'), y_test)\n",
    "trn_ds2 = copy.deepcopy(trn_ds)\n",
    "trn_ds3 = copy.deepcopy(trn_ds)\n",
    "fully_labeled_trn_ds = Dataset(X_train, y_train)\n",
    "\n",
    "lbr = IdealLabeler(fully_labeled_trn_ds)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "qs_us_sm = UncertaintySampling(trn_ds, method='sm', model=LogisticRegression())\n",
    "qs_us_lc = UncertaintySampling(trn_ds2, method='lc', model=LogisticRegression())\n",
    "qs_rnd = RandomSampling(trn_ds3)\n",
    "# qs_vr = VarianceReduction(trn_ds3, model=LogisticRegression())\n",
    "\n",
    "\n",
    "def run(trn_ds, tst_ds, lbr, model, qs, quota):\n",
    "    E_in, E_out = [], []\n",
    "\n",
    "    i = 0\n",
    "    for _ in range(quota):\n",
    "        if i % 100 == 0:\n",
    "            print i\n",
    "        # Standard usage of libact objects\n",
    "        ask_id = qs.make_query()\n",
    "        X, _ = zip(*trn_ds.data)\n",
    "        lb = lbr.label(X[ask_id])\n",
    "        trn_ds.update(ask_id, lb)\n",
    "\n",
    "        model.train(trn_ds)\n",
    "        E_in = np.append(E_in, 1 - model.score(trn_ds))\n",
    "        E_out = np.append(E_out, 1 - model.score(tst_ds))\n",
    "        i += 1\n",
    "\n",
    "    return E_in, E_out\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "quota = 2400\n",
    "\n",
    "# quota = len(y_train) - n_labeled    # number of samples to query\n",
    "\n",
    "# Comparing UncertaintySampling strategy with RandomSampling.\n",
    "# model is the base learner, e.g. LogisticRegression, SVM ... etc.\n",
    "\n",
    "E_in_1, E_out_1 = run(trn_ds, tst_ds, lbr, model, qs_us_sm, quota)\n",
    "E_in_2, E_out_2 = run(trn_ds2, tst_ds, lbr, model, qs_us_lc, quota)\n",
    "E_in_3, E_out_3 = run(trn_ds3, tst_ds, lbr, model, qs_rnd, quota)\n",
    "\n",
    "\n",
    "# Plot the learning curve of UncertaintySampling to RandomSampling\n",
    "# The x-axis is the number of queries, and the y-axis is the corresponding\n",
    "# error rate.\n",
    "\n",
    "plotly.tools.set_credentials_file(username='tonyabracadabra', api_key='6gs9i5iec7')\n",
    "\n",
    "\n",
    "trace_train_sm = go.Scatter(\n",
    "    x = range(1, len(E_in_1)),\n",
    "    y = E_in_1,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Train error / uncertainty sampling (SM)'\n",
    ")\n",
    "\n",
    "trace_train_lc = go.Scatter(\n",
    "    x = range(1, len(E_in_2)),\n",
    "    y = E_in_2,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Train error / uncertainty sampling (LC)'\n",
    ")\n",
    "\n",
    "trace_train_random = go.Scatter(\n",
    "    x = range(1, len(E_in_3)),\n",
    "    y = E_in_3,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Train error / random'\n",
    ")\n",
    "\n",
    "trace_test_sm = go.Scatter(\n",
    "    x = range(1, len(E_in_1)),\n",
    "    y = E_out_1,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Test error / uncertainty sampling (SM)'\n",
    ")\n",
    "\n",
    "trace_test_lc = go.Scatter(\n",
    "    x = range(1, len(E_in_2)),\n",
    "    y = E_out_2,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Test error / uncertainty sampling (LC)'\n",
    ")\n",
    "\n",
    "trace_test_random = go.Scatter(\n",
    "    x = range(1, len(E_in_3)),\n",
    "    y = E_out_3,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Test error / random'\n",
    ")\n",
    "\n",
    "\n",
    "a = [trace_train_sm,trace_train_lc,trace_train_random,trace_test_sm,trace_test_lc,trace_test_random]\n",
    "\n",
    "py.iplot(a, filename='plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_ds_ori = Dataset(X_train.astype('float64'), \\\n",
    "np.concatenate([y_train[:n_labeled].astype('float64'), [None] * (len(y_train) - n_labeled)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different regularization terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_ds_ori = Dataset(X_train.astype('float64'), \\\n",
    "np.concatenate([y_train[:n_labeled].astype('float64'), [None] * (len(y_train) - n_labeled)]))\n",
    "\n",
    "trn_dss = [copy.deepcopy(trn_ds_ori) for i in xrange(5)]\n",
    "qs_albl = ActiveLearningByLearning(\n",
    "         trn_dss[0], # Dataset object\n",
    "         query_strategies=[\n",
    "             UncertaintySampling(trn_dss[0], method='sm', model=LogisticRegression(C=1.)),\n",
    "             UncertaintySampling(trn_dss[0], method='sm', model=LogisticRegression(C=.01)),\n",
    "             UncertaintySampling(trn_dss[0], method='sm', model=LogisticRegression(C=.1))\n",
    "             ],\n",
    "    model=LogisticRegression(),\n",
    "    T = 2400\n",
    ")\n",
    "\n",
    "\n",
    "qs_us_sm_1 = UncertaintySampling(trn_dss[1], method='sm', model=LogisticRegression(C=1.))\n",
    "qs_us_sm_01 = UncertaintySampling(trn_dss[2], method='sm', model=LogisticRegression(C=.1))\n",
    "qs_us_sm_001 = UncertaintySampling(trn_dss[3], method='sm', model=LogisticRegression(C=.01))\n",
    "qs_random = RandomSampling(trn_dss[4])\n",
    "\n",
    "qss = [qs_albl, qs_us_sm_1, qs_us_sm_01, qs_us_sm_001, qs_random]\n",
    "\n",
    "labels = ['ALBL','C = 1', 'C = 0.1','C = 0.01', 'random']\n",
    "\n",
    "traces = []\n",
    "for i, qs in enumerate(qss):\n",
    "    trn_ds = trn_dss[i]\n",
    "    E_in, E_out = run(trn_ds, tst_ds, lbr, model, qs, quota)\n",
    "    trace_train = go.Scatter(\n",
    "    x = range(1, len(E_in)),\n",
    "    y = E_in,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Train error / ' + labels[i]\n",
    "    )\n",
    "    trace_test = go.Scatter(\n",
    "    x = range(1, len(E_in)),\n",
    "    y = E_out,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Test error / '+ labels[i]\n",
    "    )\n",
    "    traces.append(trace_train)\n",
    "    traces.append(trace_test)\n",
    "\n",
    "py.iplot(traces, filename='plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict by XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train error / ALBL'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "selected = np.array([i[1] is not None for i in trn_ds.data])\n",
    "\n",
    "X_selected = np.asarray(np.array(trn_ds.data)[selected,:][:,0].tolist())\n",
    "y_selected = np.asarray(np.array(trn_ds.data)[selected,:][:,1].tolist())\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=8, n_estimators=400, learning_rate=0.05, colsample_bytree=0.3, \\\n",
    "                        gamma=0.15, subsample=0.5).fit(X_selected,y_selected)\n",
    "# .fit(X_selected, y_selected)\n",
    "indexes_xgboost = np.argsort(gbm.feature_importances_)[::-100]\n",
    "\n",
    "y_pred_test = gbm.predict(X_test)\n",
    "y_pred_train = gbm.predict(X_train)\n",
    "\n",
    "y_pred_blind = gbm.predict(X_blind)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_blind_label = [labelMapping_reverse[i] for i in y_pred_blind]\n",
    "\n",
    "output_blind = pd.DataFrame(np.transpose(np.vstack([np.array(range(1,y_pred_blind.shape[0]+1)),y_pred_blind_label])))\n",
    "output_blind.to_csv(TAG+\"_BLINDED_PRED.csv\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from libact.query_strategies import *\n",
    "import copy\n",
    "\n",
    "trn_dss_2 = [copy.deepcopy(trn_ds_ori) for i in xrange(3)]\n",
    "\n",
    "qs_ct = QueryByCommittee(\n",
    "        trn_dss_2[0],\n",
    "        models=[\n",
    "        LogisticRegression(C=1.0),\n",
    "        LogisticRegression(C=.1),\n",
    "        LogisticRegression(C=.01)\n",
    "        ]\n",
    ")\n",
    "\n",
    "qs_albl = ActiveLearningByLearning(\n",
    "         trn_dss_2[1], # Dataset object\n",
    "         query_strategies=[\n",
    "             UncertaintySampling(trn_dss_2[1], method='sm', model=LogisticRegression(C=1.)),\n",
    "             UncertaintySampling(trn_dss_2[1], method='sm', model=LogisticRegression(C=.01)),\n",
    "             UncertaintySampling(trn_dss_2[1], method='sm', model=LogisticRegression(C=.1))\n",
    "             ],\n",
    "    model=LogisticRegression(),\n",
    "    T = 2400\n",
    ")\n",
    "\n",
    "qs_random = RandomSampling(trn_dss_2[2])\n",
    "\n",
    "qss_2 = [qs_ct, qs_albl, qs_random]\n",
    "labels_2 = [\"Commitee\", \"ALBL\", \"random\"]\n",
    "\n",
    "traces_2 = []\n",
    "for i, qs in enumerate(qss_2):\n",
    "    trn_ds = trn_dss_2[i]\n",
    "    E_in, E_out = run(trn_ds, tst_ds, lbr, model, qs, quota)\n",
    "    trace_train = go.Scatter(\n",
    "    x = range(1, len(E_in)),\n",
    "    y = E_in,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Train error / ' + labels_2[i]\n",
    "    )\n",
    "    trace_test = go.Scatter(\n",
    "    x = range(1, len(E_in)),\n",
    "    y = E_out,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Test error / '+ labels_2[i]\n",
    "    )\n",
    "    traces_2.append(trace_train)\n",
    "    traces_2.append(trace_test)\n",
    "\n",
    "py.iplot(traces_2, filename='plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
